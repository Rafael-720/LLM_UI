# LLM UI - Interface Multimodal com Voz e Chat

Uma interface web moderna e responsiva para interagir com modelos de linguagem locais (via Ollama), oferecendo suporte nativo para conversaÃ§Ã£o por voz em tempo real, transcriÃ§Ã£o de Ã¡udio e geraÃ§Ã£o de imagens.



## ğŸš€ Funcionalidades Principais

*   **ğŸ’¬ Chat com LLMs Locais**: IntegraÃ§Ã£o direta com o **Ollama** para rodar modelos como Llama 3, Mistral, Phi, etc., localmente no seu PC.
*   **ğŸ—£ï¸ Modo de Voz em Tempo Real**:
    *   **Reconhecimento de Fala (STT)**: Utiliza o **OpenAI Whisper** (com suporte a GPU/CUDA) para transcrever sua fala com alta precisÃ£o.
    *   **SÃ­ntese de Voz (TTS)**: Respostas do bot sÃ£o lidas em voz alta usando **Edge-TTS**, proporcionando uma voz natural e fluida.
    *   **DetecÃ§Ã£o de Atividade de Voz (VAD)**: O sistema detecta automaticamente quando vocÃª para de falar para enviar a mensagem, permitindo uma conversa "mÃ£os livres".
*   **ğŸ¨ GeraÃ§Ã£o de Imagens**: Crie imagens a partir de texto usando modelos **Latent Consistency Models (LCM)** via biblioteca `diffusers`, otimizados para geraÃ§Ã£o rÃ¡pida.
*   **âš¡ Performance**: Backend assÃ­ncrono construÃ­do com **FastAPI**.

## ğŸ› ï¸ Tecnologias Utilizadas

*   **Backend**: Python, FastAPI, Uvicorn.
*   **Frontend**: HTML5, Vanilla JavaScript, CSS3.
*   **IA & Modelos**:
    *   **LLM**: [Ollama](https://ollama.com/) (Llama 3, Mistral, etc.)
    *   **TranscriÃ§ao (STT)**: [OpenAI Whisper](https://github.com/openai/whisper)
    *   **Ãudio (TTS)**: [Edge-TTS](https://github.com/rany2/edge-tts)
    *   **Imagens**: [Hugging Face Diffusers](https://huggingface.co/docs/diffusers/index)

## ğŸ“‹ PrÃ©-requisitos

Antes de comeÃ§ar, certifique-se de ter instalado:

1.  **Python 3.10** ou superior.
2.  **[Ollama](https://ollama.com/)**: Deve estar instalado e rodando em segundo plano.
3.  **FFmpeg**: NecessÃ¡rio para processamento de Ã¡udio (o script de instalaÃ§Ã£o tenta configurar automaticamente, mas Ã© bom ter no sistema).
4.  **Placa de VÃ­deo NVIDIA (Opcional)**: Altamente recomendado para o Whisper e GeraÃ§Ã£o de Imagens funcionarem rapidamente.

## ğŸ”§ InstalaÃ§Ã£o e ExecuÃ§Ã£o

O projeto inclui um script automatizado para facilitar a configuraÃ§Ã£o no Windows.

1.  **Clone o repositÃ³rio** (ou baixe os arquivos):
    ```bash
    git clone https://github.com/Rafael-720/LLM_UI.git
    cd llm-ui
    ```

2.  **Execute o script de inicializaÃ§Ã£o**:
    DÃª um duplo clique no arquivo `run_windows.bat`.

    Este script irÃ¡:
    *   Verificar se o Python estÃ¡ instalado.
    *   Configurar o FFmpeg (se necessÃ¡rio).
    *   Criar um ambiente virtual (`venv`).
    *   Instalar todas as dependÃªncias (`requirements.txt`), incluindo suporte a CUDA se disponÃ­vel.
    *   Iniciar o servidor.

3.  **Acesse a AplicaÃ§Ã£o**:
    Abra seu navegador e vÃ¡ para:
    ```
    http://localhost:8000
    ```

## ğŸ“– Como Usar

### ConfiguraÃ§Ã£o Inicial
1.  Certifique-se que o **Ollama** estÃ¡ rodando (`ollama serve` no terminal ou via Ã­cone na bandeja).
2.  Na interface web, selecione o modelo de chat desejado no menu suspenso (canto superior direito).
3.  (Opcional) Clique em **Settings** âš™ï¸ para configurar o tamanho do modelo Whisper (ex: `base`, `small`, `medium`) e o dispositivo (`cuda` para GPU ou `cpu`).

### Modos de InteraÃ§Ã£o

*   **Chat de Texto**: Digite sua mensagem e pressione Enter.
*   **Microfone (TranscriÃ§Ã£o)** ğŸ¤: Clique para gravar. Clique novamente para parar. O Ã¡udio serÃ¡ transcrito para texto, mas **nÃ£o** enviado automaticamente. Ãštil para ditar mensagens longas.
*   **Modo de Voz (Conversa)** ğŸ§:
    *   Clique no Ã­cone de fone de ouvido.
    *   Fale normalmente. O sistema detectarÃ¡ o silÃªncio, enviarÃ¡ a mensagem e responderÃ¡ em Ã¡udio automaticamente.
    *   A conversa continua em loop atÃ© vocÃª desativar o modo.
*   **GeraÃ§Ã£o de Imagem** ğŸ–¼ï¸:
    *   Digite a descriÃ§Ã£o da imagem no campo de texto.
    *   Clique no Ã­cone de imagem (ao lado do microfone).

## ğŸ¤ ContribuiÃ§Ã£o

Sinta-se Ã  vontade para abrir issues ou enviar pull requests para melhorias!

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT.
